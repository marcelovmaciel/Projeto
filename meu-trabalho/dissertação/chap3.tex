\section{Entidades e Processos}

O trabalho tem por propósito explorar a emergência de distribuições de
preferências fundamentando-se no diálogo entre a Teoria Política Espacial e a
área de Dinâmicas de Opinião. Não temos por propósito um modelo que seja
preditivo, mas que capture microfundamentos relevantes, como viés de confirmação
e confiança nas crenças, e gere distribuições de preferência plausíveis, no
sentido delimitado no Capítulo 1. O trabalho propõe, portanto, um modelo que
abra a caixa-preta do processo de socialização que leva a cristalização de
direcionamentos, ou posicionamentos, ideológicos.

A Teoria Geométrica de política modela as preferências dos agentes como relações
em um espaço contínuo, as quais, em ambientes macro, são construídas por meio da
agregação das atitudes, crenças, posicionamentos, ou simplesmente opiniões dos
agentes em diferentes questões (\textit{issues}). As preferências dos agentes
numa dimensão são, assim, o sumário de um \textit{perfil ideológico} do agente
sobre questões.

Para gerar a distribuição de pontos ideais, contudo, não precisamos especificar
qual a função de utilidade centrada nele, já que não é interesse do trabalho
modelar a tomada de decisão que o pressuporia, por exemplo a escolha de um
candidato. Como discutido no Capítulo 1, é possível atribuir diferentes funções
de utilidade aos agentes, mas o pressuposto modal é que a função vai ter um
máximo e será simétrica \cite{eguia2013spatial, carroll2013structure}. Vamos
fazer uso desse pressuposto e modelar somente a emergência do ponto preferido a
partir da interação com outros agentes em várias questões. Como não é um modelo
de tomada de decisão, mas sim um modelo de surgimento de posicionamentos
ideológicos, não é necessário adicionar mais um elemento, funções de utilidade,
que simplesmente alargaria o espaço de parâmetros e não seria utilizado na
simulação. Contudo, modelos futuros que busquem ligar, por exemplo, a
distribuição de preferências com a escolha de candidatos/partidos poderiam fazer
essa atribuição.

%Assumimos, portanto, que as preferências dos
%agentes na dimensão são de pico-único, o pressuposto modal, desde
%\citeonline{black1958theory}, na literatura em modelos fortemente espaciais, e
%em trabalhos empíricos em estimação de pontos ideais \cite{carroll2013structure,
% armstrong2014analyzing, schofield1998nash}.

Pensar os agentes como tendo ideais derivados de posicionamentos em outras
questões tem por base dois fundamentos. O primeiro é que esse elemento a mais, em
comparativo aos modelos de \citeonline{deffuant2000mixing} e de
\citeonline{martins2012bayesian}, nos permite ser mais condizentes com a
literatura discutida no Capítulo 1 em contraposição à equiparação do ponto ideal
a uma opinião. Isto é, os pontos ideais dos agentes vão mudar ao longo da
simulação, mas isso ocorre devido à mudança nas suas crenças. É uma
mudança assim indireta e condizente com a noção de que a ideologia do agente é
um atributo extrínseco. O segundo fundamento é que essa modificação tem por
implicação a capacidade de adicionar outros elementos à dinâmica do modelo.

Sendo assim, cada agente na nossa população vai ter por atributo um perfil
ideológico\footnote{Nisso o modelo aproxima-se do modelo de
  \citeonline{axelrod1997dissemination}, no qual os agentes tem por atributo um
  conjunto de traços.} \(I\), onde \(I_i = (f_i(\theta_1), \ldots, f_i(\theta_n)) \). Os
elementos de \(I\) são as crenças dos agentes em cada questão. Seguindo
\citeonline{martins2012bayesian}, vamos pressupor que os agentes têm uma
probabilidade subjetiva sobre cada questão \(\theta\), e uma opinião \( o_i =
E_i[\theta]\) e incerteza \( \sigma_i^2 = E[\sigma^2] - E_ i[\theta]^2\) associados. O ponto ideal
\(x\) do agente vai ser a média aritmética\footnote{Em trabalhos futuros, é
  interessante pensar o ponto ideal como a média ponderada. Adicionar peso a
  cada questão é uma forma de modelar a importância que o indivíduo dá a ela.
  Essa é uma implicação possível ao pensarmos o agente em termos de perfil
  ideológico ao invés de uma única opinião.} das opiniões dele em \(I\). Do
ponto de vista da implementação o atributo \(I\) é reduzido a um conjunto de
pares \(I_i = ((o_{i,1},\sigma_{i,1}^2), \ldots, (o_{i,n}, \sigma_{i,n}^2) )\), sendo \(\sigma^2\)
global e \(o\) retirado de uma distribuição uniforme, e o posicionamento
ideológico do agente é dado por \(x_i = \frac{1}{n}\sum_{k=1}^{n} o_k\).


O tempo é discreto e estamos interessados nas alterações ao longo prazo da
configuração dos \(x\) sob diferentes combinações de parâmetros, tendo em vista
as interações dos agentes \cite{acemoglu2011opinion} \footnote{Como vamos
  definir longo prazo e analisar o modelo é tema da seção metodológica.}. Para
tal, a regra de interação é em díades. A cada iteração da simulação um dos
agentes vai ser escolhido e vai interagir com um de seus vizinhos, a princípio
num grafo completo imposto exogenamente (estabeleço na condição
  inicial quais os vizinhos). A interação é assim assíncrona (os agentes
atualizam seus atributos em momentos distintos) e sequencial (um agente atualiza
por vez) \cite{wilensky2015introduction}. A dependência dos resultados em
relação ao número de agentes e de crenças vai ser explorada.

Quando os agentes interagem \(i\) atualiza sua opinião e incerteza em
alguma\footnote{Qual questão vão ``debater'' vai ser definido por meio de um
  sorteio sem viés. Uma outra implicação possível, a ser adicionada em trabalhos
  futuros, é considerar um viés nessa seleção, o que representaria saliência no
  sentido dado por \citeonline{zaller1992simple}: qual questão os agentes estão
  dando atenção, isto é, qual questão está mais acessível na memória deles.}
questão segundo as equações 2.3 e 2.5. Isso significa que existem dois tipos
possíveis de agente: atualizam somente \(o\) ou atualizam também \(\sigma^2\). Esse é
um atributo global para cada repetição da simulação\footnote{Onde repetição
  significa rodar a simulação sob uma semente aleatória \cite{laver2011party}.}.


Vamos considerar duas variantes de \(p\): na primeira ele vai ser uma variável
global \(0 < p < 1 \), a mesma para todos os agentes, assim como em
\citeonline{martins2009bayesian}; na segunda, consideramos a possibilidade de
que os agentes levem em conta ou não a opinião do vizinho em uma questão em
particular a partir do conhecimento do ponto ideal do outro agente, de forma
que: \(p_{ij}(t) = 1 - |x_i(t) - x_j(t)|\). Isto é, nesse \(p\) alternativo o
agente \(i\) vai considerar a verossimilhança de um valor declarado pelo seu
vizinho \(j\) segundo um \(p\) derivado da média do posicionamento ideológico de
\(j\). Por exemplo, suponha que o agente \(j\) é um eleitor conservador. O
agente \(i\) vai levar em conta essa informação geral sobre \(j\) para
considerar a probabilidade do agente \(j\) estar falando algo correto em
questões particulares.

Os agentes também vão reconsiderar suas opiniões e certezas sobre as questões
segundo uma probabilidade \(\rho\). Do ponto de vista teórico, estamos considerando
a possibilidade de fatores não relacionados à influência social levarem o agente
a mudar seu posicionamento sobre questões \cite{flache2017, lorenz2017modeling}.
Do ponto de vista metodológico, \citeonline{macy2015signal} argumenta que
pequenas perturbações no comportamento local dos agentes pode levar a mudanças
drásticas nas propriedades sistêmicas. Particularmente, consideram que adicionar
ruído pode: eliminar equilíbrios frágeis, o que reduz o conjunto de resultados e
tornando-os mais previsíveis; e embora aumente a heterogeneidade local isso pode
acabar facilitando interações sociais que reduzem a diversidade global
\cite[p.323]{macy2015signal}. Vamos fazer o pressuposto mais simples que os
desvios aleatórios são independentes na população e sem viés quanto à opinião do
agente, de forma que pressupomos um ruído uniformemente distribuído
\cite{Pineda-2009, lorenz2017modeling}.


\section{Parâmetros-Chave}

Os parâmetros-chave para configuração e inicialização do modelo, cujos valores
seguem \citeonline{martins2008continuous}, \citeonline{deffuant2000mixing} e
\citeonline{lorenz2017modeling}, são:

\begin{itemize}
\item A população de \(500 < N < 5000\) agentes;
\item O número de questões \(1 \leq \text{n\_issues} \leq 10\); 

\item As incertezas \(0.01 \leq \sigma_i \leq 0.5\);
  \begin{itemize}
  \item A incerteza é, na condição inicial, a mesma para todos os agentes;
  \item Vamos considerar versões em que os agentes atualizam as incertezas e que
    não atualizam.
  \end{itemize}

\item O parâmetro de confiança \(0.1 \leq p \leq 0.99\);
  
  \begin{itemize}
  \item Vamos considerar variantes em que o \(p\) é global ou em que o \(p\) é
    calculado para cada interação;
  \end{itemize}

\item O tipo dos agentes:
  \begin{itemize}
  \item Se eles atualizam somente \(o\) ou se atualizam também \(\sigma^2\);
    \item Se eles atualizam somente \(o\) será chamado de Caso I, se atualizam
      também \(\sigma^2\) por sua vez é o Caso II;
  \end{itemize}

\item A probabilidade de reconsideração \(0.0 \leq \rho  \leq 0.1\);
  
\end{itemize}

\section{Inicialização e Iteração}

A inicialização da simulação depende dos parâmetros-chave apresentados. Na
condição inicial temos uma população de \(N\) agentes, que tem por atributos: um
conjunto de pares \(I_i = ((o_{i,1},\sigma_{i,1}^2), \ldots, (o_{i,n},\sigma_{i,n}^2))\), onde
o número de questões, \(n\), é uma variável global, cada \(o\) é retirado de uma
distribuição uniforme \(U([0,1])\) e \(\sigma^2\) é uma variável global; um posicionamento
ideológico, ou ponto ideal, \(x_i = \frac{1}{n} \sum_{k = 1}^n o_{i,k} \); e um
conjunto de vizinhos, o qual depende de qual a rede os agentes estão, a
princípio um grafo completo.

 Uma iteração da simulação, a
passagem de digamos \(t=2\) para \(t=3\), é dada pela aplicação de dois
procedimentos: a atualização via influência social e a atualização aleatória.
Uma repetição da simulação é a aplicação iterativa desses dois procedimentos ao
longo de um tempo \(t \).

O procedimento de influência social é o seguinte: escolhemos um agente \(i\)
da população. Então escolhemos um de seus vizinhos, \(j\). Sorteamos uma das
questões \(k \in (1,\ldots,n)\), e logo em seguida selecionamos os \((o_{i,k},o_{j,k})\) e
\((\sigma_{i,k}^2,\sigma_{j,k}^2)\) correspondentes à questão. A partir daqui temos duas
opções, \(i\) atualiza somente \(o_{i,k}\) ou também atualiza \(\sigma_{i,k}^2\),
segundo as equações 2.3 e 2.5. Essa regra é um parâmetro global da simulação,
o que significa que a cada repetição todos os agentes atualizam suas crenças
segundo a mesma regra.

Ademais, temos o ruído. Novamente escolhemos um agente \(i\) da população.
Sorteamos uma questão e selecionamos \(o\) e \(\sigma^2\) correspondentes. Sorteamos
um \(\xi\) retirado de uma distribuição uniforme \(U([0,1])\) e se \(\xi < \rho\) \(i\)
muda \(o\) para um valor retirado também de uma uniforme e \(\sigma^2\) volta ao
valor global.Os \(x_i\), o objeto de interesse de análise, são atualizados
sempre que ocorrerem mudanças nas crenças dos agentes.



\section{Metodologia de Análise}

Dentre as diversas formas de analisar um ABM a análise de sensibilidade global
se destaca como uma forma de ter uma compreensão ampla, geral, do comportamento
do modelo \cite{north2007managing}. Contudo, o  alto custo computacional de varrer
o espaço de parâmetros faz com que só seja possível, na maioria dos casos, se
seguirmos métodos formais da literatura de análise de sensibilidade
\cite{railsback2012agent}. Esses métodos trazem o benefício de determinar como
selecionar subconjuntos de todas as combinações de parâmetros, reduzindo o
número de realizações necessárias da simulação e de trazerem formas sistemáticas
de interpretar os resultados \cite{railsback2012agent}.

Quanto à amostragem uma estratégia comum são as parametrizações de Monte Carlo:
sortear valores de parâmetros usados para as realizações das simulações a partir
de distribuições uniformes nos intervalos de valores dos parâmetros
\cite{laver2011party}. O problema dessa estratégia é que o espaço de parâmetros
não é coberto igualmente, havendo a possibilidade de pontos de acumulação ou
espaços vazios \cite{pereda2017brief}.

\citeonline{saltelli2008global} argumenta que para manter uma dispersão equitativa
dos pontos no espaço de parâmetros é necessário um algoritmo que enviese a
seleção de novos pontos para mantê-los afastados dos pontos já presentes. Desta
forma vamos usar o método de Saltelli de amostragem, dado que garante a partição
equitativa do espaço de parâmetros \cite{herman2017salib}. Especificamos então
um \(n\) base a partir do qual o ``sampler'' gera n * (2d + 2), onde \(d\) é o
número de parâmetros. No nosso caso \(d = 5\), pois vamos ter como parâmetros :
N (população), número de questões (codificado como n\_issues ), \(p\), \(\sigma\) e
\(\rho\). Vamos tratar se os agentes atualizam \(o\) ou se atualizam também \(\sigma\)
como dois casos. Para garantir um coeficiente de erro baixo no cálculo
subsequente dos índices de sensibilidade especificamos um \(n\) base de
\(5000\), de forma que para cada caso rodamos \(60.000\) parametrizações.

Uma vez especificado o método de amostragem especificamos uma medida do sistema
para que possamos analisá-lo \cite{railsback2012agent}. Escolhemos o desvio
padrão dos pontos ideais após \(1.000.000\) iterações como output para
análise\footnote{Testamos diversas parametrizações com n\_issues \(= 1\) e
  observamos que a partir de \(50.000\) iterações a implementação replica os
  resultados de \citeonline{martins2009bayesian}.}, dado que nos diz o quão
concentradas ou dispersos são os pontos ideais da população. Para a análise,
seguimos \cite{ten2016sensitivity} e combinamos gráficos de dispersão com
índices de sensibilidade. 

Os índices de sensibilidade utilizados são os índices de Sobol\footnote{Tanto a
  amostragem quanto a análise de sensibilidade são feitas usando o pacote de
  Python SALib \cite{herman2017salib}.}, particularmente índices de Sobol de
primeira ordem e totais \cite{saltelli2008global}. Os índices de Sobol decompõe
o impacto dos parâmetros na variância do \textit{output} de interesse. Os
índices de primeira ordem incluem contribuições lineares e não-lineares dos
parâmetros, mas não efeitos interativos \cite{ten2016sensitivity}. Já índices
totais incluem todos os efeitos de ordem maior decorrentes das interações entre
os parâmetros \cite{saltelli2008global}.



\section{Resultados}

Rodamos então \(60.000\) parametrizações por \(1.000.000\) de iterações tendo
por \(Y\), o \textit{output} de interesse, a variância do ponto ideal da
população (\(\text{Ystd}\)) após as iterações. São \(5\) os parâmetros de input
: o número de agentes (\(N\)), o número de questões (\(\text{n\_issues}\)), o
parâmetro de confiança (\(p\)), a incerteza (\(\sigma\)), e o ruído \(\rho\), nos
limiares apresentados na seção Parâmetros-Chave.


A Figura \ref{fig:Yshist} apresenta a dispersão dos pontos ideais nos dois casos:
\begin{figure}[H]
  \centering
  \includegraphics{ims/distYs.png}
  \caption{Output (desvio padrão dos pontos ideais) }
  \label{fig:Yshist}
\end{figure}

A Figura \ref{fig:Yshist}  nos leva a interpretar  que a aplicação iterativa do
procedimento do modelo, em geral, deixa a distribuição de opiniões menos
dispersa, com uma maior concentração das parametrizações em outputs de baixa
dispersão (entre 0.0 e 0.1). Contudo, isso não nos informa qual parâmetro é
responsável por isso, ou quais os valores de concentração (centrais ou extremos).



\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{ims/mutoregressions/regressionmutatingon_issues.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{ims/mutoregressions/regressionmutatingoN.png}
    \end{subfigure}

    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{ims/mutoregressions/regressionmutatingop.png}
      \end{subfigure}
          \begin{subfigure}[b]{0.49\textwidth}
            \includegraphics[width=\textwidth]{ims/mutoregressions/regressionmutatingorho.png}
      \end{subfigure}

                \begin{subfigure}[b]{0.49\textwidth}
            \includegraphics[width=\textwidth]{ims/mutoregressions/regressionmutatingosigma.png}
    \end{subfigure}
    \caption{Gráfico de dispersão para 60.000 parametrizações no Caso I.}
    \label{fig:scatter1}
    Fonte:Elaboração própria.
\end{figure}

A primeira pergunta pode começar a ser respondida por meio de gráficos de
dispersão. A partir da Figura\footnote{Os gráficos de dispersão para o Caso II
  são semelhantes. Estão no apêndice.} \ref{fig:scatter1} podemos inferir que há
uma relação negativa entre os parâmetros \(\text{n\_issues}, p, \sigma \) e a
dispersão dos pontos ideais (\( \text{Ystd}) \). A relação entre \(p\) e \(\sigma\)
são explicadas pelo fato de agentes que são mais incertos e ``confiam'' mais na
opinião dos outros agentes vão convergir mais rápido para a mesma opinião.
\todo[inline,color = yellow!10]{puxar de martins 2009 aqui a discussão das
  equações}

Já a relação entre número de questões e menor dispersão se dá pelo fato que
quanto mais questões mais centrado vai ser o ponto ideal, uma vez que é a média
aritmética das opiniões. Como estamos retirando as opiniões em cada questão de
uma U[0,1] quanto mais vezes fazemos esse sorteio, pela Lei dos Grandes Números,
mais centrada a média aritmética vai ser do valor esperado da distribuição
(0.5). O parâmetro \(\rho\), o ruído, por sua vez, tem uma relação positiva com a
dispersão do sistema. Interessante notar, contudo, que o tamanho da população
parece não ter relação com o desvio padrão dos pontos ideais da população.

A intensidade dos parâmetros na variância da medida do sistema (Ystd) fica mais
claro na Figura \ref{fig:sobol1}:

\begin{figure}[H]
  \centering
  \includegraphics{ims/barplotmuto5k.png}
  \caption{Índices de Sobol de sensibilidade}
  \label{fig:sobol1}
\end{figure}

Como mostra a Figura \ref{fig:sobol1} o parâmetro \(N\) não tem impacto sobre a
variância de \(Ystd\), de forma que podemos tratá-lo como uma constante para
análise subsequentes. A figura mostra que a maior parte da variância na
dispersão dos pontos ideais pode ser explicada pelos parâmetros \(\sigma\) e
\(\text{n\_issues}\). Além disso há pouca diferença entre os índices de primeira
ordem e os índices totais, o que implica que há poucos efeitos interativos entre
os parâmetros. Por fim os coeficientes de erro são pequenos, como mostra a
Tabela 1, tendo em vista que a análise foi feita a partir de 60.000
parametrizações selecionadas por meio do método de Saltelli. O Caso II exibe o
mesmo comportamento, com a diferença que nele o parâmetro \(\sigma\) tem maior
impacto do que no Caso I (mas mantêm-se a direção e a importância qualitativa dos
parâmetros).


\begin{table}[H]
\centering
\caption{Índices de Sobol e coeficientes de erro respectivos}
\label{my-label}
\begin{tabular}{|l|r|r|r|r|}
\hline
\rowcolor[HTML]{C0C0C0} 
Parâmetros & S1        & S1\_conf & ST       & ST\_conf \\ \hline
N          & -0.000105 & 0.003153 & 0.002526 & 0.000578 \\ \hline
n\_issues  & 0.289362  & 0.026289 & 0.366176 & 0.022603 \\ \hline
p          & 0.070374  & 0.015140 & 0.103448 & 0.008719 \\ \hline
\(\sigma\) & 0.421365  & 0.030780 & 0.512525 & 0.030992 \\ \hline
\(\rho\)   & 0.103914  & 0.016065 & 0.144819 & 0.012853 \\ \hline
\end{tabular}
\end{table}


Dado que os parâmetros \(\sigma\) e \(\text{n\_issues}\) são os que mais explicam a
variância da dispersão dos pontos ideais eles são o foco de análise subsequente.
Estabelecemos \(N = 500\). Passamos a usar então o número de opiniões finais
como medida do sistema.





%%% Local  Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
